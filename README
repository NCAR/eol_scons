/**

@page config-page Software Configuration Framework

@section toc Table of Contents

@li @ref overview
@li @ref implementation
@li @ref eolsconspackage
@li @ref globalvariables
@li @ref globaltools
@li @ref debugging
@li @ref eolsconsdetails
@li @ref configuration
@li @ref doxygen
@li @ref subsets
@li @ref history
@li @ref comparison

@section overview Overview

This software configuration framework provides the 'build harness' for
building a source directory tree of libraries and executables.  The goal is
to make it easy to separate software into logical and reusable modules
which can be compiled and shared within a single directory tree, allowing
libraries to be shared transparently from either internal or external
(installed) locations.

The main objective is a modular, flexible, and portable build system.
Given various libraries and executables in the source tree, where each
builds against some subset of the libraries and some subset of external
packages, the build for a program in the source tree should only need to
name its required packages without regard for the location of those
packages.  For example, a program needing the 'util' library specifies
'util' as a package requirement which causes the proper libraries and
include paths to be added to the environment.  The 'util' library itself
may require other libraries, and those libraries should also be added to
the environment automatically.  A program which builds against the 'util'
library should not need to know that the util library must also link
against library 'tools'.  Each module is responsible for publishing (or
exporting) the build setup information which other modules would need to
compile and link against that module, thus isolating the build
configuration in each source directory from changes in the location or
configuration of its dependencies.

In the source tree, each module resides in its own directory, either
directly under the top-level directory or under subdirectories.  The
convention is that each module represents a namespace, so that as much as
possible the directory partitioning can match the namespace partitioning,
and header files can be included with the namespace in the path.  For
example, all of the dataspace library is defined in the 'dataspace' C++
namespace, so all public headers are included with "dataspace/" in the
header path.  One consequence of this convention is that if new modules are
attached to the source tree with their namespace name, then their header
files will be accessible without any change to the default include paths in
the build configuration.  Keeping namespace and source module in sync also
helps in navigating the source.


@section implementation SCons Implementation

The current build framework is based on SCons (http://www.scons.org) and
called eol_scons.  eol_scons is a python package and a set of scons tools
which extends the standard SCons.  Every component within the source tree
as well as all external packages have a particular tool which configures a
scons Environment for building against that component.  The eol_scons
package provides a table of global targets that SConscript files throughout
the source tree can use to find dependencies, without knowing where those
dependencies are built or installed.  For example, the tool for a library
like netcdf, whether installed on the system or built within the source
tree, defines a function for configuring the build environment.  Sometimes
the tools are loaded from a tool file from the common `site_scons/site_tools`
directory, sometimes via a Python script named `tool_{toolname}.py`, and 
other times the tool is a function defined within the SConscript
file which builds the library or dependency.  Either way, the tools are
genuine scons tools, so they can be applied to an Environment by the
usual means.  In particular, they can be applied with the Tool() method or
passed in the tools list when the Environment is constructed.


@subsection externaltools External Tools

Below is an example of a very simple tool from eol_scons for building
against the fftw library.  The `fftw` tool is a tool file in the
`site_scons/site_tools` directory under the top directory of the project
source tree.  It's a shared tool file because it's always an external
dependency.

@code
def generate(env):
  # Hardcode the selection of the threaded fftw3, and assume it's installed
  # somewhere already on the include path, ie, in a system path.
  env.Append(LIBS=['fftw3_threads','fftw3'])

def exists(env):
    return True
@endcode

A source module which depends on `fftw` could include this tool in
a SConscript Environment file like so:

@code
env = Environment(tools = ['default', 'fftw'])
@endcode

@subsection internaltools Internal Tools

Tools can also be defined locally, to extend beyond the tools which are
defined in `site_scons/site_tools`.  This is as simple as `def`-ing and
`Export`-ing a SCons function, the name of which is the name of the tool.
This can happen in a SConscript file, in which case the tool will be defined
as soon as the SConscript file is loaded.  However, the preferred method is to
create a file named `tool_{toolname}.py` in the directory containing the
tool's components.  The `eol_scons` package will try to find and load such a 
tool definition from within the local heirarchy when a tool is requested, 
so there's no need to explicitly load a specific `SConscript` file before 
requesting the tool.  Here's an example tool definition from the ELDORA tree, 
where a tool named `ddslib` is defined in file `ddslib/tool_ddslib.py`:

@code
#
# Rules to build ddslib and export it as a SCons tool
#
tools = ['opendds', 'doxygen']
env = Environment(tools = ['default'] + tools)

def ddslib(env):
    env.AppendLibrary('EldoraDds')
    env.AppendDoxref('EldoraDds')
    env.AppendUnique(CPPPATH = ['#/ddslib',])
    env.Require(tools)

Export('ddslib')

libEldoraDds, sources, headers = env.DdsLibrary('EldoraDds.idl', env)

html = env.Apidocs(sources + headers, DOXYFILE_FILE = "#/Doxyfile")

Default(libEldoraDds)
@endcode

Creation of a tool requires only that a function be `def`-ed and
`Export`-ed.  Everything else shown above is the details for actually
building the library provided by the `ddslib` tool.  Simpler tools would
just use the normal SCons builder methods like `env.Program()` and
`env.Library()`.

The `ddslib` example shows how tools are not limited to affecting the
library and include paths through the Envrionment's construction variables.
Tools can also modify the methods available on an Environment to provide
new conveniences or functionality.  For example, the 'doxygen' tool adds
the 'Apidocs()' build wrapper to the Environment.

Also note how the tool requirements are recursive.  When another
environment requires tool 'ddslib', the `EldoraDDS` library is added to the
library path.  In addition, all the requirements of the EldoraDDS library
are added by the call to `env.Require(tools)`.  In particular, requiring
the 'opendds' tool (which was required to build the EldoraDDS library) will
add the OpenDDS libraries to the library path which EldoraDDS will need to
link successfully.

Here's how a `SConscript` might show that show that it requires 'ddslib':

@code
tools = ['ddslib', 'qt4']
env = Environment(tools = ['default'] + tools)
@endcode

The above excerpt creates an Environment which loads a tool
called 'ddslib' (along with 'qt4').  If the tool 'ddslib' had not been found 
in the global exports as 'ddslib' or 'PKG_DDSLIB', then eol_scons would have 
looked for a file named `tool_ddslib.py` in the local heirarchy and loaded 
it to generate the tool, otherwise it would have continued to look via the 
normal SCons tool mechanism.

Note that modules which use the 'ddslib' component do not need
to know the dependencies of the ELDORA DDS library.  If the library
adds another external library as a dependency, then that dependency will
be added in the `ddslib` tool definition.

Here's an example from the 'logx' tool.  This is an external tool file,
meaning it is contained in the site_scons/site_tools on the normal scons
tool path, rather than being located within a source directory in a
`tool_*.py file`.  The tool_.py files are loaded like regular SConscript
files with the SConscript() function, whereas tool modules are imported as
python modules.  A tool module must define a function called 'generate' to
modify an environment.  The generate() module function serves the same
purpose as the python tool function defined in a `SConscript` or
`tool_*.py` file.

@code
def generate(env):
    env.AppendLibrary ("logx")
    if env.GetGlobalTarget("liblogx"):
	      env.AppendDoxref("logx")
    else:
	      env.AppendDoxref("logx:/net/www/software/raddx/apidocs/logx/html")
    env.Tool ('log4cpp')
@endcode

Since the logx library requires log4cpp, the logx tool automatically sets
up the log4cpp dependencies with the 'env.Tool()' call.

The logx tool appends the liblogx target to the list of libraries and then
requires the log4cpp tool, which in turn appends the log4cpp dependencies
to the environment.  Any other module in the source tree which applies only
the logx tool to its environment will in turn have log4cpp applied
automatically.  If the logx library someday requires another library or
other include paths, none of the other modules in the source tree which use
logx will need to change their SConscript configuration.

Unlike in the log4cpp.py tool file, liblogx is a library built _within_ the
source tree, and so the actual liblogx target node is added to the LIBS
construction variable.  The liblogx target node must be retrieved from a
global registry of such nodes maintained by the eol_scons package.  The
logx tool could just as well determine whether the logx library should be
linked from within the source tree or from some external installation, and
then modify the environment accordingly.  The source module which depends
upon the logx library need not change either way.


@section eolsconspackage The eol_scons Package

The eol_scons package extends the standard SCons framework for EOL
software developments.

@subsection sitesconsdirectory site_scons Directory

The eol_scons modules and tools reside in a directory meant to be shared
among software projects.  The idea is that this directory should hold the
files for a project build framework which are not specific to a particular
project.  The directoy can be linked into a source tree, checked out
separately, or referenced using 'svn:extnerals'.  SCons automatically
checks for a directory called 'site_scons' in the top directory, where the
SConstruct file is located.  So by checking out the eol_scons directory
tree into a directory called 'site_scons', the integration and extension of
SCons happens automatically.

@subsection extensions SCons Extensions

This package extends SCons in three ways.  First of all, it overrides or
adds methods for the SCons Environment class.  See the _ExtendEnvironment()
function to see the full list.

Second, this package adds a set of EOL tools to the SCons tool path.  Most
of the tools are for configuring and building against third-party software
packages.

Lastly, this module itself provides an interface for configuring and
controlling the eol_scons framework outside of the Environment methods.
The following sections cover the public functions.

@subsection examples Examples

Underneath the site_scons directory is an 'examples' directory.  This
directory contains example SConstruct, SConscript, and tool files lifted
directly from the 'aeros' project source tree, just without the source.
These files can be used as templates for new projects, new source
directories, or as reference examples for some of the techniques mentioned
here.

@li @ref examples/SConstruct
@li @ref examples/logx/tool_logx_example.py
@li @ref examples/datastore/SConscript
@li @ref examples/aeros/SConscript

@section globalvariables GlobalVariables()

The GlobalVariables() function returns the global set of variables
(formerly known as options) available in this source tree.  Recent versions
of SCons provide a global Variables singleton by default, but this method
supplies a default config file path.  The first Variables instance to be
constructed with @p is_global=1 (the default) becomes the singleton
instance, and only that constructor's settings (for config files and
arguments) take effect.  All other Variables() constructors will return the
singleton instance, and any constructor parameters will be ignored.  So if
a particular source tree wants to set its own config file name, it can
specify that path in a Variables() constructor in the top-level SConstruct,
so that instance is created before the default created by eol_scons:

SConstruct:
@code
variables = Variables("my_settings.py")
@endcode

If no singleton instance is created explicitly by in project SConsctruct
file, then the default created by eol_scons will take effect.  The default
eol_scons Variables() instance specifies a config file called 'config.py'
in the top directory.

@section globaltools Global Tools

The eol_scons environment adds the notion of global tools, or tools which
can be specified in upper-level environments which will be applied to all
subdirectory Environments.  Originally their use was limited to the
top-level SConstruct file.  It could create an environment which specified
a set of tools that the project would apply to each Environment created.
With the advent of nested projects, the global tools are now mapped by the
particular directory of the SConscript or SConstruct file which created the
Environment.  Each Environment can specify its own set of global tools.
Those tools, plus the global tools of any Environments created in parent
directories, will be applied to all Environments created in any
subdirectories.  In other words, nested project trees can extend the global
tools set with the tools needed by its subdirectories, but those tools will
not be applied in other directories of the project.  One project can
contain other source trees each with their own SConstruct file.  Those
SConstruct files can be loaded with normal SConscript calls, but their
global tools list will only affect the directories within the subproject.

A typical SConstruct file appends a global tool function and other tools to
its global tools.  Global tools are the hook by which the SConsctruct file
can provide the basic configuration for an entire source tree if needed,
without requiring a redundant set of tools to specified every time an
Environment is created within a project.  Global tools are specific to the
directory in which an Environment is created.  They can be modified in 
one of two ways.

The global tools can be extended by passing the list of tools in the
GLOBAL_TOOLS construction variable when creating an Environment:

@code
  env = Environment(tools = ['default'],
                    GLOBAL_TOOLS = ['svninfo', 'qtdir', 'doxygen', Aeros])
@endcode

Or, for an environment has already been created, the global tool list can
be modified like below:

@code
  env.GlobalTools().extend([Aeros, "doxygen"])
@endcode

However, in the above method, the new tools will *not* be applied to the
Environment.  The tools *are* applied when passed in the GLOBAL_TOOLS
keyword in an Environment constructor.

Global tools are never applied retroactively to existing environments, only
when environments are created.  Once an Environment has been created, tools
must be applied using the Tool() or Require() methods.

@section debugging Debugging

Debug(msg) prints a debug message if the global debugging flag is true.

SetDebug(enable) sets the global debugging flag to @p enable.

The debugging flag in eol_scons can also be set using the SCons Variable
eolsconsdebug, either passing eolsconsdebug=1 on the scons command line or
setting it in the config.py file like any other variable.

@section eolsconsdetails Technical Details on Tools and eol_scons

The eol_scons package overrides the standard Tool() method of the SCons
Environment class to customize the way tools are loaded.  First of all, the
eol_scons Tool() method only loads a tool once.  The standard SCons method
reloads a tool through the python 'imp' module every time a tool name is
referenced, and this seems excessive and unnecessary, besides breaking the
assumption in many eol_scons that a tool is only loaded once.

Second, eol_scons at one point tried to only apply tools once.  Standard
SCons keeps track of which tools have been loaded in an environment in the
TOOLS construction variable, but it always applies a tool even if it's been
applied already.  The TOOLS variable is a dictionary of Tool instances
keyed by the module name with which the tool was loaded (imported).
However, I think I found this name to be inconsistent depending upon how
and where a tool is referenced.  So eol_scons.Tool() uses its own
dictionary keyed just by the tool name.  Applying a tool only once seems to
work, however it might violate some other assumptions about setting up a
construction environment.  For example, dependencies may need to have their
libraries listed last, after the last component which requires them, but
this won't happen if the required tool is required twice but only applied
the first time.  More experience might determine if it makes more sense to
only apply tools once, but for now eol_scons follows the prior practice of
applying tools multiple times, which is consistent with the standard SCons
behavior.

The eol_scons package also adds a Require() method to the SCons
Environment.  The Require() mehod simply loops over a tool list calling
Tool().  The customized eol_scons Tool() method returns the tool that was
applied, as opposed to the SCons.Environment.Environment method which does
not.  This makes it possible to use Require() similarly to past usage,
where it returns the list of tools which should be applied to environments
built against the component:

@code
env = Environment(tools = ['default'])
tools = env.Require(Split("doxygen qt"))

def this_component_tool(env):
    env.Require(tools)

Export('this_component_tool')
@endcode

It should be possible to make tools robust enough to only execute certain
code once even when loaded multiple times, but that hasn't been explored
much to find a solution that's not more work than it's worth.  [As far as
I'm concerned, it seems legitimate to assume that a module or tool is only
ever loaded once.  That's why the eol_scons Tool() method overrides the
scons standard method to only load a tool once.]

A similar issue occurs if a module is imported under two names.  For
example, the 'chdir.py' module can be imported either as 'eol_scons.chdir'
or just 'chdir'.  It appears that python will load that module under both
names, causing any one-time code to be executed twice.

Tools are python modules and not SConscript files, so certain functions and
symbols are not available in the global namespace as they are in SConscript
files.  In particular, instead of Split(), use string.split().  Export()
and Import() should not be used.  Consider replacing them with a
construction variable in the environment.

To refer to tools defined in SConscript files in other directories within a
source tree, Export() the tool function in the SConscript file, then
Import() it in the SConscript files which need it.  See the examples
directory.

@section configuration Configuration

The eol_scons framework contains a tool called 'prefixoptions'.  It used to
be part of the environment by default, but now it's a separate tool.
However, the tool is still loaded by default unless the GlobalTools() list
is modified first.  The tool adds build options called @p OPT_PREFIX and @p
INSTALL_PREFIX.  @p OPT_PREFIX defaults to '$DEFAULT_OPT_PREFIX', which in
turn defaults to '/opt/local'.  A source tree can modify the default by
setting DEFAULT_OPT_PREFIX in the environment in the global tool.  Run
'scons -h' to see the help information for all of the local options.  You
can set an option on the command line like this:

@code
scons -u OPT_PREFIX=/opt
@endcode

Or you can set it for good in a file called config.py in the top directory:

@code
# toplevel config.py
OPT_PREFIX="/opt"
@endcode

The @p OPT_PREFIX path is automatically included in the appropriate
compiler options.  Several of the smaller packages expect to be found there
by default (eg, netcdf), and so they don't add any paths to the environment
themselves.

The @p INSTALL_PREFIX option is the path prefix used by the installation
methods of the Pkg_Environment class:

@code
InstallLibrary(source)
InstallProgram(source)
InstallHeaders(subdir, source)
@endcode

Therefore the above methods do not exist in the environment instance until
the prefixoptions tool has been loaded.

The @p INSTALL_PREFIX defaults to the value of @p OPT_PREFIX.

It is also possible for any package script or SConscript to add more
configuration options to the build framework.  The eol_scons package
creates a single instance of the SCons Variables class, and that is the
instance to which the @p OPT_PREFIX and @p INSTALL_PREFIX options are
added.  The eol_scons function GlobalVariables() returns a reference to the
global Variables instance, so further options can be added at any time by
adding them to that instance.

For example, the spol package script adds an option SPOL_PREFIX:

@code
print "Adding SPOL_PREFIX to options."
eol_scons.GlobalVariables().AddVariables (
	PathVariable('SPOL_PREFIX', 'Installation prefix for SPOL software.',
		   '/opt/spol'))
@endcode

The option is only added once, the first time the spol.py tool is loaded.
After that, every time the spol tool is applied it calls Update() on the
target environment to make sure the spol configuration options are setup in
that environment.

@code
	eol_scons.GlobalVariables().Update(env)
@endcode

Finally, the end of the top-level SConstruct file should contain a call to
the SCons Help() function using the help text from the GlobalVariables()
instance.  This ensures that any options added by any of the modules in the
build tree will appear in the output of 'scons -h'.

@code
options = env.GlobalVariables()
options.Update(env)
Help(options.GenerateHelpText(env))
@endcode

@section doxygen SCons Doxygen

There are two separate doxygen builders: one for a Doxyfile and one for
running Doxygen.  Using separate builders facilitates multiple kinds of
Doxygen output from the same source, such as public API documentation for
users of a library and documentation of the private interfaces for library
developers.  The default configuration limits the documentation to the
public API.

The Apidocs() method is added to an environment instance when the doxygen
tool is applied.  It simplifies use of the doxygen builder.  Given a list
of sources, the builder generates both the Doxyfile and doxygen targets.
The doxygen output is put in a subdirectory of the directory named by the
APIDOCSDIR construction variable, "#apidocs" by default.

There is no alias for doxygen.  Instead, name the top-level documentation
directory as the target to update all of the documentation underneath it:

@code
cd raddx
scons apidocs
@endcode

The Doxyfile builder generates a Doxyfile using the sources as the INPUT,
and it accepts several parameters to customize the configuration.  The
builder expects one target, the name of the doxygen config file to
generate.  The generated config file sets directory parameters relative to
the target directory, so it expects Doxygen to run in the same directory as
the config file.  The documentation output will be written under that same
directory.

The Doxyfile builder uses these environment variables:

@code
    DOXYFILE_FILE

    The name of a doxygen config file that will be used as the basis for
    the generated configuration.  This file is copied into the destination
    and then appended according to the DOXYFILE_TEXT and DOXYFILE_DICT
    settings.

    DOXYFILE_TEXT

    This should hold verbatim Doxyfile configuration text which will be
    appended to the generated Doxyfile, thus overriding any of the default
    configuration settings.
                        
    DOXYFILE_DICT

    A dictionary of Doxygen configuration parameters which will be
    translated to Doxyfile form and included in the Doxyfile, after the
    DOXYFILE_TEXT settings.  Parameters which specify files or directory
    paths should be given relative to the source directory, then this
    target adjusts them according to the target location of the generated
    Doxyfile.

    The order of precedence is DOXYFILE_DICT, DOXYFILE_TEXT, and
    DOXYFILE_FILE.  In other words, parameter settings in DOXYFILE_DICT and
    then DOXYFILE_TEXT override all others.  A few parameters will always
    be enforced by the builder over the DOXYFILE_FILE by appending them
    after the file, such as OUTPUT_DIRECTORY, GENERATE_TAGFILE, and
    TAGFILES.  This way the template Doxyfile generated by doxygen can
    still be used as a basis, but the builder can still control where the
    output gets placed.  If any of the builder settings really need to be
    overridden, such as to put output in unusual places, then those
    settings can be placed in DOXYFILE_TEXT or DOXYFILE_DICT.

    Here are examples of some of the Doxyfile configuration parameters
    which typically need to be set for each documentation target.  Unless
    set explicitly, they are given defaults in the Doxyfile.
    
    PROJECT_NAME        Title of project, defaults to the source directory.
    PROJECT_VERSION     Version string for the project.  Defaults to 1.0
@endcode


The Doxygen builder uses these environment construction variables with the
given defaults:

@code
    env['DOXYGEN'] = 'doxygen'
    env['DOXYGEN_FLAGS'] = ''
    env['DOXYGEN_COM'] = '$DOXYGEN $DOXYGEN_FLAGS $SOURCE'
@endcode    


Here are two typical examples for using the doxygen builders.  The first
sets the PROJECT_NAME by passing it in the DOXYFILE_DICT construction
variable.

@code
sources = Split("""
 Logging.cc LogLayout.cc LogAppender.cc system_error.cc
""")
headers = Split("""
 CaptureStream.h EventSource.h Logging.h Checks.h
 system_error.h
""")

doxconfig = { "PROJECT_NAME" : "logx library" }
    
env.Apidocs(sources + headers, DOXYFILE_DICT=doxconfig)
@endcode

This example passes Doxyfile configuration text directly using the
DOXYFILE_TEXT construction variable.  The source files to be scanned by
doxygen are passed to the builder as the 'source' parameter.  Each source
file is added to the INPUT parameter in the generated Doxyfile.  This may
seem more cumbersome than using Doxygen's recursive directory and file
pattern features.  However, strict control on the source files has several
benefits.  For one, it makes the dependency's explicit so that SCons can
reliably recreate documentation when source files change.  Also, new source
files which might still be under development will not be accidentally
included in the public API documentation.  Likewise, source files for
internal utilities and private interfaces will not be part of the
documentation unless explicitly included.  The Doxygen builders allow
multiple variations for documentation, from internal details to the public
API, and its likely that those variations work from different sets of
source files.

@code
doxyfiletext = """
PROJECT_NAME           = "DataSpace Library"

MACRO_EXPANSION        = YES
EXPAND_ONLY_PREDEF     = YES
EXPAND_AS_DEFINED = DATAMEMORYTYPETRAITS 
EXPAND_AS_DEFINED += ENTITY_OBJECT ENTITY_VISIT ENTITY_PART ENTITY_COLLECT
EXPAND_AS_DEFINED += ENTITY_BASIC
"""

env.Apidocs(sources+headers, DOXYFILE_TEXT=doxyfiletext)
@endcode

As a final example, here is how the doxygen builders are used to generate
the top-level documentation:

@code
doxyconf = """
OUTPUT_DIRECTORY       = apidocs
HTML_OUTPUT            = .
RECURSIVE              = NO
SOURCE_BROWSER         = NO
ALPHABETICAL_INDEX     = NO
GENERATE_LATEX         = NO
GENERATE_RTF           = NO
GENERATE_MAN           = NO
GENERATE_XML           = NO
GENERATE_AUTOGEN_DEF   = NO
ENABLE_PREPROCESSING   = NO
CLASS_DIAGRAMS         = NO
HAVE_DOT               = NO
GENERATE_HTML          = YES
"""

df = env.Doxyfile (target="apidocs/Doxyfile",
                   source=["mainpage.dox","REQUIREMENTS","config/README"],
                   DOXYFILE_TEXT = doxyconf)
dx = env.Doxygen (target="apidocs/index.html", source=[df])
@endcode

The targets are a little different in this case, since the html output (and
thus the index.html file) is being placed directly into the apidocs
directory rather than into a subdirectory.  Therefore the two builders are
setup explicitly rather than with Pkg_Environment.Apidocs().

The SCons doxygen support is defined in the tool file
site_scons/site_tools/doxygen.py.

The Doxyfile builder also takes care of cross-references between modules
and between external packages.  The tool for a package can append a doxygen
reference to the DOXREF construction variable using the AppendDoxref()
method.  If the module is internal, then it only needs to append its module
name:

@code
	env.AppendDoxref("logx")
@endcode

If the package is external but has html documentation online, then the
reference should include the root of the html documentation:

@code
    env.AppendDoxref("log4cpp:%s/doc/log4cpp-%s/api" % (prefix, version))
@endcode

When the Doxyfile builder parses this reference, it will automatically run
the 'doxytag' program to generate a tag file from the external
documentation.

If instead the HTML documentation is online somewhere and a tag file for
it has already been generated, then the reference to that documentation can
be specified explicitly, typically in the SConstruct  file:

@code
    env.SetDoxref('QWT_DOXREF','$TAGDIR/qwt-5.tag',
              'http://qwt.sourceforge.net')
@endcode

In this example from aeros, there is a set of tag files stored in the
source tree, and the TAGDIR variable points to that directory.


@section subsets Building Subsets of the Source Tree

With large source trees, scons can be very slow to read all of the
subsidiary SConscript files and scan all of the source files and implicit
dependencies.  It is not like hierarchical makes, where the build only
proceeds down from the current subdirectory.  Instead, scons builds always
start from the top.  So to speed up iterative compiles with scons, here are
a few ways to build only subsets of the source tree.

The most obvious way is to eliminate subdirectories from the source tree.
scons issues a warning for every SConscript file it cannot find, but it
continues anyway.  The SConstruct file can actually check for the existence
of each SConscript subdirectory and skips the ones that do not exist, just
to avoid the warning message.

Some EOL SConstruct files support a SUBDIRS option.  The SUBDIRS option
contains the specific list of subdirectories whose SConscript files should
be loaded.  When working on a particular subset of the raddx tree, say
spol, it is possible to limit builds to the current subdirectory and any
modules on which it depends.  Unfortunately, for the moment those modules
need to be known in advance and explicitly included in SUBDIRS.  For
example, if working in the dataspace directory, this command builds only
the dataspace library and the logx and domx libraries which it requires:

@code
scons -u SUBDIRS="logx domx dataspace"
@endcode

Note this is different than running this command:

@code
scons -u .
@endcode

The above command only builds the current directory, but it first loads and
scans all of the SConscript files in the entire project.  The SUBDIRS
version only loads SConscript files from three subdirectories, so it is
much faster.

Like other options, SUBDIRS can be specified on the command-line or in the
configuration file, config.py.

Some components define their tool function within the SConscript file in
their source directory, rather than in the site_scons directory.  To build
any modules which depend on such packages, the package's subdirectory must
be included in the SUBDIRS list.  Otherwise the package's tool function
will never be defined.

Help on the SUBDIRS option shows up in the -h output from scons:

@code
SUBDIRS: The list of subdirectories from which to load SConscript files.
    default:
  rtfcommon logx acex domx inix dorade dbx rtf_disp
  eldora/eldora
  radd eldora rdow acex/RingBuf spol
  lidar
@endcode

With eol_scons, individual SConscript files do not need to import a root
environment from which to create their own environment.  Instead they use
normal SConscript conventions, except the underlying environment instance
is modified by the 'default' tool.  So it is possible to build logx
completely separately from the rest of the source tree with something like
this:

@code
cd logx
scons -f SConscript --site-dir ../site_scons
@endcode

With a few tweaks to the SConscript file, it is possible for many of the
shared packages to use the same SConscript file to build both within a
source tree and standalone.

@section history History

I found myself wishing I had copies of small utility source files in
multiple projects, and in fact originally just used copies.  As I started
to add features in one copy that I wanted in the other copies, I realized I
needed some kind of framework to allow me to easily reuse a single, shared
copy of the utility sources.  The utilities I wanted were mostly extensions
to much larger outside packages, like the DOM XML library Xerces-C or the
C++ logging package log4cpp based on Log4J.  So I did not want to throw all
the utilities into a single library which would have lots of major
dependencies.  I thought that would detract from the library's convenience
and its likelihood of being reused.  Instead I settled on trying to find a
way to share easily and conveniently many smaller, more focused libraries.

The result is basically very similar to the framework I put in place for
the MAPR software tree, which due to the KDevelop IDE used automake and
autoconf and started out divided into several smaller projects.  That work
in turn led me to borrow some things from the KDE development framework.  I
wished there were something better to base this on than the autoconf tools,
but I did not know what that would be.  Qmake seems to be difficult to
extend to a larger project or with new make variables and rules.  Perhaps
JAM or ANT would have been better, but autoconf seemed to be the more
widely used, and there are huge projects like KDE and GCC rich with working
examples from which techniques can be pulled.  Given that more and more
projects are likely to run on both Windows and UNIX, it would be useful if
the build system supported compiles on both platforms.  I don't know how/if
automake/autoconf could handle that, but SCons does.


@section comparison Comparison Between SCons and Autoconf

Here's my input into the build tool comparison mix--more of an abstract
overview than a feature comparison.  I'll admit there are aspects to both
make tools and scons that I don't like, but I think scons is more on the
right track.  Make together with shell scripting can be made to handle very
complex multi-directory builds and dependencies, however it's limitation is
that Makefiles must describe all of the dependencies, rules, and relations
statically.  Dynamic checking and hierarchical builds require recursive
makes (or gnu make).  All of the tools on top of make like autoconf,
automake, and Imake were built to allow more dynamic generation of
dependencies, rule templates, and hierarchical (modular) builds while
sticking to the portable Makefile format, the make program, and Bourne
shell scripting for actually running the build commands.  This works well
to a point but requires the incorporation and close cooperation of several
tools (m4, cpp, sh, make, and various sh scripts), all of which must be
carefully crafted to be portable between operating systems, especially
Windows.

So the advantage of scons is that all of the same funcationality can be
self-contained in a single, portable scripting language--python. The
build dependencies are not described in yet another static syntax, but
instead they are assembled through calls to a standard and mostly intuitive
scripting API built within python.  The assembly of the dependencies and
build rules on any particular build invocation can be very dynamic and
runtime configurable.  No preformatting of Makefiles or preconfiguration of
the build environment is required.  I think this makes scons slower by
pushing all of that processing back to each and every build run, but it is
also what allows scons to be more thorough and dynamic.  Ant got the
portability idea right by encapsulating build rules and their specification
with XML and Java, but I think it went wrong by adding yet another static
dependency format in the use of XML.  I think Ant would have been better to
follow the scons model of using Java for both build phases: first describe
the rules and dependencies for a build environment using portable Java
scripting like beanscript, then run the build engine on that environment
using Java.  The idea is the same: use a portable but powerful runtime like
Java or python to provide both dynamic dependencies and rule execution.
Describe the dependencies and write the rules in the same language.

On the other hand, the self-containment of scons lends to some of its
current drawbacks, from my perspective.  For example, automatic dependency
scanning is built-in but primitive.  It scans source files for include
dependencies using regular expression matching, so it fails to catch
dependencies which only exist with certain preprocessor
definitions. However, that could be become more accurate as scons develops.
Also, scons is very strict about thoroughly describing and checking all
dependencies and only executing build actions when dependencies are
outdated.  This makes it harder to use scons to run auxiliary build actions
which do not have such clear cut notions of dependencies, such as
generating documentation (doxygen), cleaning, and installing.  Scons does
scale well to managing the dependencies of a large multi-directory project
like the raddx tree, but only in dependency complexity and not in
performance.  I'm still trying to get it to scale back down to building
small subsets of the source tree separately and quickly, which was always
easy and fast with hierarchical makefiles.

For both autoconf and scons I've ended up grafting some of my own desired
extensions on top of them to support more modular build environments.  One
way or another I'll be able to get scons to do what I want.  So as for me,
I don't see any reason to go back to autoconf or Makefiles.



**/
